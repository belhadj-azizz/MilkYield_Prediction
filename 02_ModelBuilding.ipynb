{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will serve to firstly treat the variables that we want to include in the model and start trying out different predictive algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\henib\\.cache\\kagglehub\\datasets\\shahhet2812\\cattle-health-and-feeding-data\\versions\\1\n",
      "Path to dataset files: C:\\Users\\henib\\.cache\\kagglehub\\datasets\\shahhet2812\\cattle-health-and-feeding-data\\versions\\1\n",
      "\n",
      "Files in dataset directory:\n",
      "  global_cattle_disease_detection_dataset.csv\n",
      "  global_cattle_milk_yield_prediction_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shahhet2812/cattle-health-and-feeding-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Print the path (you already have it)\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# List all files in the downloaded directory\n",
    "files = os.listdir(path)\n",
    "print(\"\\nFiles in dataset directory:\")\n",
    "for f in files:\n",
    "    print(f\"  {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "cattle = pd.read_csv(os.path.join(path, 'global_cattle_milk_yield_prediction_dataset.csv'))\n",
    "df = cattle.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of unnecessary columns \n",
    "health_features = ['FMD_Vaccine', 'Brucellosis_Vaccine', 'HS_Vaccine', 'BQ_Vaccine','Anthrax_Vaccine', 'IBR_Vaccine', 'BVD_Vaccine', 'Rabies_Vaccine']\n",
    "non_relevant_features = ['Date', 'Farm_ID', 'Cattle_ID', 'Previous_Week_Avg_Yield'] #Previous Week Avg Yield serves as a proxy for the target so we must drop otherwise it'll take the highest weight since it's highly correlated with the target\n",
    "df.drop(columns=health_features+non_relevant_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Milk_Yield_L']\n",
    "X = df.drop(columns=['Milk_Yield_L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- #\n",
    "#       Encoding Function       #\n",
    "# ----------------------------- #\n",
    "\n",
    "def one_hot_encoding(train_df, test_df, categorical_cols):\n",
    "    \"\"\"\n",
    "    Fit OneHotEncoder on training data and transform both training and test sets.\n",
    "    Ensures no data leakage and consistent columns between train and test.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "        Training DataFrame.\n",
    "    test_df : pd.DataFrame\n",
    "        Test DataFrame.\n",
    "    categorical_cols : list\n",
    "        List of categorical columns to encode.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train_encoded : pd.DataFrame\n",
    "        Encoded training data.\n",
    "    X_test_encoded : pd.DataFrame\n",
    "        Encoded test data.\n",
    "    encoder : OneHotEncoder\n",
    "        The fitted encoder (for potential reuse or inverse transform).\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Fit on train, transform both\n",
    "    train_encoded = encoder.fit_transform(train_df[categorical_cols])\n",
    "    test_encoded  = encoder.transform(test_df[categorical_cols])\n",
    "    \n",
    "    # Get encoded feature names\n",
    "    encoded_cols = encoder.get_feature_names_out(categorical_cols)\n",
    "    \n",
    "    # Convert to DataFrame and keep indices aligned\n",
    "    train_encoded_df = pd.DataFrame(train_encoded, columns=encoded_cols, index=train_df.index)\n",
    "    test_encoded_df  = pd.DataFrame(test_encoded, columns=encoded_cols, index=test_df.index)\n",
    "    \n",
    "    # Drop original categorical columns and concatenate\n",
    "    X_train_encoded = pd.concat([train_df.drop(columns=categorical_cols), train_encoded_df], axis=1)\n",
    "    X_test_encoded  = pd.concat([test_df.drop(columns=categorical_cols), test_encoded_df], axis=1)\n",
    "    \n",
    "    return X_train_encoded, X_test_encoded, encoder\n",
    "\n",
    "# ----------------------------- #\n",
    "#        Scaling Function       #\n",
    "# ----------------------------- #\n",
    "\n",
    "def scale_numerical(train_df, test_df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Fit MinMaxScaler on training numerical columns and transform both training and test sets.\n",
    "    Prevents data leakage and keeps columns consistent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "        Training DataFrame.\n",
    "    test_df : pd.DataFrame\n",
    "        Test DataFrame.\n",
    "    numerical_cols : list\n",
    "        List of numerical column names to scale.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_train_scaled : pd.DataFrame\n",
    "        Scaled training data.\n",
    "    X_test_scaled : pd.DataFrame\n",
    "        Scaled test data.\n",
    "    scaler : MinMaxScaler\n",
    "        The fitted scaler (for reuse or inverse transformation).\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Fit on train, transform both\n",
    "    train_scaled = scaler.fit_transform(train_df[numerical_cols])\n",
    "    test_scaled  = scaler.transform(test_df[numerical_cols])\n",
    "    \n",
    "    # Convert back to DataFrames with proper column names and index\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=numerical_cols, index=train_df.index)\n",
    "    test_scaled_df  = pd.DataFrame(test_scaled, columns=numerical_cols, index=test_df.index)\n",
    "    \n",
    "    # Replace original columns with scaled versions\n",
    "    X_train_scaled = train_df.copy()\n",
    "    X_test_scaled  = test_df.copy()\n",
    "    \n",
    "    X_train_scaled[numerical_cols] = train_scaled_df\n",
    "    X_test_scaled[numerical_cols]  = test_scaled_df\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "# ----------------------------- #\n",
    "#   Regression CV Function      #\n",
    "# ----------------------------- #\n",
    "\n",
    "def cross_validate_regression(model, X, y, categorical_features, numerical_features, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform K-Fold cross-validation with OneHotEncoder and MinMaxScaler preprocessing\n",
    "    for regression tasks only.\n",
    "\n",
    "    Returns R², MAE, MSE, RMSE, and MAPE across folds.\n",
    "    \"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics = {\n",
    "        \"r2\": [],\n",
    "        \"mae\": [],\n",
    "        \"mse\": [],\n",
    "        \"rmse\": [],\n",
    "        \"mape\": []\n",
    "    }\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        # Split\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Encode + scale\n",
    "        X_train_enc, X_test_enc, _ = one_hot_encoding(X_train, X_test, categorical_features)\n",
    "        X_train_final, X_test_final, _ = scale_numerical(X_train_enc, X_test_enc, numerical_features)\n",
    "\n",
    "        # Train + predict\n",
    "        model.fit(X_train_final, y_train)\n",
    "        preds = model.predict(X_test_final)\n",
    "\n",
    "        # Compute metrics\n",
    "        r2 = r2_score(y_test, preds)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        mse = mean_squared_error(y_test, preds)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = mean_absolute_percentage_error(y_test, preds)\n",
    "\n",
    "        # Save metrics\n",
    "        metrics[\"r2\"].append(r2)\n",
    "        metrics[\"mae\"].append(mae)\n",
    "        metrics[\"mse\"].append(mse)\n",
    "        metrics[\"rmse\"].append(rmse)\n",
    "        metrics[\"mape\"].append(mape)\n",
    "\n",
    "        print(f\"Fold {fold}: R²={r2:.4f}, MAE={mae:.4f}, RMSE={rmse:.4f}, MAPE={mape:.4f}\")\n",
    "\n",
    "    # Average metrics\n",
    "    avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "    print(\"\\n✅ Average metrics across folds:\")\n",
    "    for k, v in avg_metrics.items():\n",
    "        print(f\"{k.upper()}: {v:.4f}\")\n",
    "\n",
    "    return avg_metrics, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'Breed', 'Region', 'Country', 'Climate_Zone',\n",
    "    'Management_System', 'Lactation_Stage', 'Feed_Type', 'Season', 'Milking_Interval_hrs'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'Age_Months', 'Weight_kg', 'Feed_Quantity_kg',\n",
    "    'Water_Intake_L', 'Walking_Distance_km', 'Grazing_Duration_hrs',\n",
    "    'Rumination_Time_hrs', 'Resting_Hours', 'Ambient_Temperature_C', 'Days_in_Milk', 'Humidity_percent', 'Housing_Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: R²=0.5906, MAE=2.8355, RMSE=3.6844, MAPE=446307627500792.9375\n",
      "Fold 2: R²=0.5976, MAE=2.8143, RMSE=3.6613, MAPE=454211984906556.1875\n",
      "Fold 3: R²=0.5939, MAE=2.8354, RMSE=3.6872, MAPE=465863069597894.4375\n",
      "Fold 4: R²=0.5929, MAE=2.8233, RMSE=3.6724, MAPE=452285898466502.3125\n",
      "Fold 5: R²=0.5948, MAE=2.8062, RMSE=3.6568, MAPE=460054564505736.6250\n",
      "\n",
      "✅ Average metrics across folds:\n",
      "R2: 0.5940\n",
      "MAE: 2.8229\n",
      "MSE: 13.4867\n",
      "RMSE: 3.6724\n",
      "MAPE: 455744628995496.5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "model = LinearRegression()\n",
    "avg_metrics, all_metrics = cross_validate_regression(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    categorical_features=categorical_features,\n",
    "    numerical_features=numerical_features,\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: R²=0.4040, MAE=3.2466, RMSE=4.4457, MAPE=497996561119688.3125\n",
      "Fold 2: R²=0.4084, MAE=3.2421, RMSE=4.4393, MAPE=485571044813711.2500\n",
      "Fold 3: R²=0.4037, MAE=3.2569, RMSE=4.4680, MAPE=502393154298185.6250\n",
      "Fold 4: R²=0.4021, MAE=3.2477, RMSE=4.4507, MAPE=490620062338136.9375\n",
      "Fold 5: R²=0.4050, MAE=3.2237, RMSE=4.4312, MAPE=493001246965202.4375\n",
      "\n",
      "✅ Average metrics across folds:\n",
      "R2: 0.4046\n",
      "MAE: 3.2434\n",
      "MSE: 19.7756\n",
      "RMSE: 4.4470\n",
      "MAPE: 493916413906984.8750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize model (you can tweak max_depth or other hyperparameters)\n",
    "model = DecisionTreeRegressor(max_depth=30, random_state=42)\n",
    "\n",
    "# Run cross-validation\n",
    "avg_metrics, all_metrics = cross_validate_regression(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    categorical_features=categorical_features,\n",
    "    numerical_features=numerical_features,\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: R²=0.6452, MAE=2.6445, RMSE=3.4359, MAPE=471019603137895.6875\n",
      "Fold 2: R²=0.6468, MAE=2.6388, RMSE=3.4327, MAPE=474712644662331.0625\n",
      "Fold 3: R²=0.6441, MAE=2.6308, RMSE=3.4276, MAPE=467894907766088.9375\n",
      "\n",
      "✅ Average metrics across folds:\n",
      "R2: 0.6454\n",
      "MAE: 2.6380\n",
      "MSE: 11.7789\n",
      "RMSE: 3.4320\n",
      "MAPE: 471209051855438.5625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,       # number of trees\n",
    "    max_depth=None,         # allow trees to expand fully\n",
    "    min_samples_leaf=100,   # prevent overfitting on leaves\n",
    "    n_jobs=-1,              # use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Run cross-validation\n",
    "avg_metrics, all_metrics = cross_validate_regression(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    categorical_features=categorical_features,\n",
    "    numerical_features=numerical_features,\n",
    "    n_splits=3  # fewer folds for faster computation on large dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
